{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentence embeddings with infersent\n",
    "[InferSent](https://github.com/facebookresearch/InferSent) is a sentence embedding model created by Facebook Research using the [SNLI](https://nlp.stanford.edu/projects/snli/) dataset. The whole thing has been released under a [non-commercial license](https://github.com/facebookresearch/InferSent/blob/master/LICENSE) and is starting to gain some traction as it's used in more and more interesting contexts. \n",
    "Unsurprisingly, sentence embeddings are word embeddings for sentences. When a sentence is passed through the network, it is assigned a position in sentence space in which other sentences with similar semantic meanings also sit. The 4096 dimensional feature vector which is produced can be interpreted to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "nltk.download('punkt')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load InferSent model\n",
    "We've stored the relevant infersent code locally in `InferSent.py` so that it can be intuitively imported (as below), but the original can be found as `models.py` in the source repo. We also need to load the model weights in `infersent2.pkl` and the word vectors on which the model was trained from `crawl-300d-2M.vec`. The InferSent API is simple enough to use, and in only a few lines of code we have a working sentence embedding model. Note that this _is_ a model - we're not loading a dictionary and just looking up known keys here as we do with most word vectors. Each time we call `infersent_model.encode()`, the text is passed through a neural network to produce a new, unique embedding which the model had not necessarily seen as part of its training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InferSent import InferSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH =  '/mnt/efs/models/infersent2.pkl'\n",
    "\n",
    "params_model = {'bsize': 1024, \n",
    "                'word_emb_dim': 300, \n",
    "                'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', \n",
    "                'dpout_model': 0.0, \n",
    "                'version': 2}\n",
    "\n",
    "infersent_model = InferSent(params_model)\n",
    "infersent_model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_PATH = '/mnt/efs/nlp/word_vectors/fasttext/crawl-300d-2M.vec'\n",
    "infersent_model.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infersent_model.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infersent_model = infersent_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load coco captions\n",
    "We'll use the captions from the well known [COCO dataset](http://cocodataset.org/) to demonstrate InferSent's effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/efs/images/coco/annotations/captions_val2014.json') as f:\n",
    "    meta = json.load(f)\n",
    "    \n",
    "captions = pd.DataFrame(meta['annotations']).set_index('image_id')['caption'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embed captions with infersent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = infersent_model.encode(captions, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(len(captions))\n",
    "\n",
    "embedding = embeddings[index].reshape(1, -1)\n",
    "query_caption = captions[index]\n",
    "query_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = cdist(embedding, embeddings, 'cosine').squeeze()\n",
    "closest_captions = captions[np.argsort(distances)]\n",
    "closest_captions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above shows the power of modern sentence embedding models which integrate the semantic meaning encoded in word vectors over traditional retrieval methods like TF-IDF or BM25.\n",
    "\n",
    "A great example is the query `'a rainbow is in the sky over an empty stretch of road'`.  \n",
    "The fourth result (following a few about rainbows) is `'there is a green street light hanging over this empty intersection'`.\n",
    "Very few of the most significant words in those sentences are exact matches, but the scenes they describe are extremely similar.\n",
    "\n",
    "\n",
    "# where infersent breaks\n",
    "While infersent is capable of encoding an incredible amount of subtlety in medium length sequences, it really struggles to encode that same level of meaning in short sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word_embedding = infersent_model.encode(['doctor'])\n",
    "distances = cdist(single_word_embedding, embeddings, 'cosine').squeeze()\n",
    "closest_captions = captions[np.argsort(distances)]\n",
    "closest_captions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This poses the reverse of the problem posed at the start of this notebook. While word-vector space is only able to meaningfully encode single word queries, infersent is only able to encode longer queries.  \n",
    "One might suggest a pairing of the models, where at query-time, a one-word search is sent to the word-vector model and a multi-word search is sent to the sentence-embedding model. This might solve the problem of being able to encode arbitrary length sequences, but the space _must_ be shared in order to return consistent results.\n",
    "\n",
    "In other words, we're eventually going to have to create our own, custom sentence embedding model if we're going to DeViSE our images into a meaningful search space. Nevertheless, in the next notebook we'll ensure that applying the DeViSE principle to sentence embedding space still works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
