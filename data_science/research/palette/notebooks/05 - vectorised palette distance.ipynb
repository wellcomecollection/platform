{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need for speed\n",
    "While the results from the palette-based search are great, the palette-unshuffling is a relatively expensive process, and the colour-distance computation seems like something that could be done much more efficiently at scale. Notebook 04 becomes cripplingly slow at 5000 images, and the total number of images currently in the collection is approx. 120,000. Clearly if this is going to scale, the approach needs to change.  \n",
    "In this notebook I'll try to cut down on the expense while retaining the goodness of the results. It's less important as we've already got the theory down and the _actual_ implementation will probably differ significantly (lots and lots of precomputing), but it's a nice experiment and test of my linear algebra abilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a few more images than usual,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 5000\n",
    "path_to_images = '../data/small_images/'\n",
    "\n",
    "random_ids = np.random.choice(os.listdir(path_to_images), \n",
    "                              n_images, \n",
    "                              replace=False)\n",
    "\n",
    "random_ids = np.sort(random_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build palettes for our images as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_palette(palette_colours, image_size=100, big=False):\n",
    "    palette_size=len(palette_colours)\n",
    "    \n",
    "    scale = 1\n",
    "    if big: scale = 5\n",
    "    \n",
    "    stretched_colours = [(lab2rgb(np.array(colour.tolist() * image_size * image_size * scale)\n",
    "                                  .reshape(image_size * scale, image_size, 3)) * 255)\n",
    "                         .astype(np.uint8) \n",
    "                         for colour in palette_colours]\n",
    "    \n",
    "    palette_array = (np.hstack(stretched_colours)\n",
    "                     .reshape((image_size * scale, \n",
    "                               image_size * palette_size, \n",
    "                               3)))\n",
    "\n",
    "    return Image.fromarray(palette_array)\n",
    "\n",
    "def get_palette(image, palette_size=5, image_size=75):\n",
    "    image = image.resize((image_size, image_size),\n",
    "                         resample=Image.BILINEAR)\n",
    "    lab_image = rgb2lab(np.array(image)).reshape(-1, 3)\n",
    "    clusters = KMeans(n_clusters=palette_size).fit(lab_image)\n",
    "    return clusters.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and build the `image_dict` and `palette_dict` as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {}\n",
    "palette_dict = {}\n",
    "\n",
    "for image_id in tqdm(random_ids):\n",
    "    try: \n",
    "        image = Image.open(path_to_images + image_id)\n",
    "        \n",
    "        if len(np.array(image).shape) != 3:\n",
    "            image = Image.fromarray(np.stack((image,)*3, -1))\n",
    "        \n",
    "        image_dict[image_id] = image\n",
    "        palette_dict[image_id] = get_palette(image)\n",
    "    except: \n",
    "        pass\n",
    "\n",
    "image_ids = np.sort(list(image_dict.keys()))\n",
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear assignment\n",
    "I initially assumed that I would have to reassign palette order for every image palette pair individually, or _at least_ for each row of the matrix at once. However, we can get quite close by pre-computing the assignment for all palettes according to a single palette, and indexing off that new reordered set without any further reordering. Most rearrangements seem to depend largely on the `L` component of LAB space, so we can get close for the vast majority of palette pairs. As long as the chosen palette's differences occupy the full range of L-space. This works well for `(greyscale, greyscale)` pairs and `(greyscale, colourful)` pairs. The only real trouble is when we have a `(colourful, colourful)` pair. While this represents a very small share of the available matches, it's arguably the most important type. Nevertheless, we'll try it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_distance(colour_1, colour_2):\n",
    "    return sum([(a - b) ** 2 for a, b in zip(colour_1, colour_2)]) ** 0.5\n",
    "\n",
    "\n",
    "def assignment_switch(query_palette, palette_dict):\n",
    "    rearranged = []\n",
    "    for other_palette in palette_dict.values():\n",
    "        distances = [[colour_distance(c1, c2)\n",
    "                      for c2 in other_palette]\n",
    "                     for c1 in query_palette]\n",
    "        \n",
    "        _, rearrangement = linear_sum_assignment(distances)\n",
    "        rearranged.append([other_palette[i] for i in rearrangement])\n",
    "\n",
    "    return np.array(rearranged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_palette = palette_dict[np.random.choice(image_ids)]\n",
    "display_palette(query_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rearranged = assignment_switch(query_palette, palette_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_dict = dict(zip(image_ids, rearranged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerunning the cell below a few times will give you a sense of how well the distribution of palettes is matched by this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_palette(rearranged[np.random.choice(len(rearranged))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorised palette_distance\n",
    "We can significantly speed up the computation by reformatting the `palette_distance()` problem to cover a full row of palettes at once (ie comparing one `query_palette` to every other palette in one function call). It involves some sneaky maths, and we need to make sure that the palettes have all been ordered to match the `query_palette` (or approximately so, as above).  \n",
    "Note that because we've embraced `numpy` throughout the computation, we'll also gain some giant speedups by throwing the work onto a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorised_palette_distance(rearranged, query_palette):\n",
    "    query = query_palette.reshape(-1, 1, 3)\n",
    "    palettes = [p.squeeze() for p in np.split(rearranged, 5, axis=1)]\n",
    "\n",
    "    colour_distances = np.stack([cdist(q, p, metric='cosine') \n",
    "                                 for q, p in zip(query, palettes)])\n",
    "    \n",
    "    palette_distances = np.sum(colour_distances.squeeze(), axis=0)\n",
    "    return palette_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the similarity matrix for 5000 images the old way would have taken around 3 hours. The function above generates almost exactly the same results in <30 seconds. The scaling is also demonstrably better. A distance matrix for 15,000 images now takes ~3 minutes to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_distances = pd.DataFrame()\n",
    "\n",
    "for query_id in tqdm(image_ids):\n",
    "    distances = vectorised_palette_distance(rearranged, palette_dict[query_id])\n",
    "    palette_distances[query_id] = pd.Series(dict(zip(image_ids, distances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(palette_distances);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while the approximate-ness of the computation is frustrating, I think the speedup is huge enough to justify giving this a go. Here's a larger sample of similar images for a randomly chosen query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_palette(palette_dict[query_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 300\n",
    "n_similar = 49\n",
    "size = int(n_similar ** 0.5)\n",
    "\n",
    "big_image = np.empty((int(res * size), int(res * size), 3)).astype(np.uint8)\n",
    "grid = np.array(list(itertools.product(range(size), range(size))))\n",
    "\n",
    "most_similar_ids = palette_distances[query_id].sort_values().index.values[1 : n_similar+1]\n",
    "similar_images = [image_dict[image_id].resize((res, res), resample=Image.BILINEAR) \n",
    "                  for image_id in most_similar_ids]\n",
    "\n",
    "for pos, image in zip(grid, similar_images):\n",
    "    block_t, block_l = pos * res\n",
    "    block_b, block_r = (pos + 1) * res\n",
    "    \n",
    "    big_image[block_t : block_b, block_l : block_r] = np.array(image)\n",
    "\n",
    "Image.fromarray(big_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that these results are pretty great. While it might not be worth the drop in fidelity if everything's being pre-computed (arguable...), it's probably worth doing this if we ever have to do the computation live. The second part will be especially helpful if users want to search the collection according to a new, custom palette.\n",
    "\n",
    "# Vectorised reassignment\n",
    "I'm not going to do this now because it's a much harder problem and one that I don't really _need_ to solve, but I'm almost certain there's a way of vectorising the linear assignment problem to be applied row-wise too. Doing so would match the output of this notebook exactly to the previous one, and would also deliver a pretty giant overall speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_distances.to_pickle('../src/api/palette_distances.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../src/api/palettes.pkl', 'wb') as f:\n",
    "    pickle.dump(palette_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../src/api/palettes.pkl', 'rb') as f:\n",
    "    print(np.array(list(pickle.load(f).values())).shape    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
