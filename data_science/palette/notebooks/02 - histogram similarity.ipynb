{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity\n",
    "Now that we can produce colour palettes for images, we can move on to the second task - asserting similarity between images based on the colours present within them.  \n",
    "For the task of producing notebooks, researching previous literature alone was sufficient to produce satisfactory results. However, because of the difference between our domain and more typical image datasets, I think it's worth implementing a few different approaches in code to determine which is most appropriate/effective. We'll start with histograms.\n",
    "\n",
    "### Image histograms\n",
    "As we saw in the last notebook, images are composed of pixels, and the colour of those pixels can be represented by three numbers (alternatively seen as coordinates in colour space). We can stack the pixels in an image to produce a table of three columns or channels (traditionally R, G, and B, where each channel can take on a value between 0 and 255 denoting its intensity). \n",
    "A common technique to assert the 'makeup' of an image is to produce a _histogram_ of these channels, counting the number of times that each intensity appears in each channel. Our goal in this notebook is to determine an effective way of comparing these histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (20, 15)\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cosine\n",
    "from umap import UMAP\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets randomly load in a few images and get a visual sense of the distribution of colours/tones/styles across our chosen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 1000\n",
    "path_to_images = '../data/small_images/'\n",
    "\n",
    "image_ids = np.random.choice(os.listdir(path_to_images), n_images, replace=False)\n",
    "images = [Image.open(path_to_images + image_id) for image_id in tqdm(image_ids)]\n",
    "images = [Image.fromarray(np.stack((image,)*3, -1))\n",
    "          if len(np.array(image).shape) != 3 else image\n",
    "          for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 75\n",
    "size = int(n_images ** 0.5)\n",
    "\n",
    "height = int(resolution * size)\n",
    "width = int(resolution * size)\n",
    "\n",
    "big_image = np.empty((height, width, 3)).astype(np.uint8)\n",
    "grid = np.array(list(itertools.product(range(size), range(size))))\n",
    "sq_images = [image.resize((resolution, resolution)) for image in images]\n",
    "\n",
    "for pos, image in zip(grid, sq_images):\n",
    "    block_t, block_l = pos * resolution\n",
    "    block_b, block_r = (pos + 1) * resolution\n",
    "    \n",
    "    big_image[block_t : block_b, block_l : block_r] = np.array(image)\n",
    "\n",
    "Image.fromarray(big_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting histograms\n",
    "Let's produce a histogram and get a feel for the kind of data we're working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[np.random.choice(len(images))]\n",
    "hist = image.histogram()\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is what our raw histogram data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(hist).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here it is split out into its three colour channels in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b = np.split(np.array(hist), 3)\n",
    "\n",
    "pd.DataFrame({'r': r, 'g': g, 'b': b}).plot(color=['#333399', '#339933', '#993333']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A naive start\n",
    "Lets blunder straight in with the simplest approach possible. We'll produce a historgram for each image as one long 756-dimensional vector and then brute force the cosine similarity of each image with every other image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = [image.histogram() for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_similarity = pd.DataFrame(data=[[cosine(h_1, h_2)\n",
    "                                       for h_1 in histograms] \n",
    "                                      for h_2 in tqdm(histograms)],\n",
    "                                index=image_ids,\n",
    "                                columns=image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can display the similarity matrix as a heatmap, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(naive_similarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = dict(zip(image_ids, images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now pretty easy to use our similarity matrix to look up the most similar images to a given images. We select a random image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then grab the column in the matrix which holds similarity measures for our `query_id`. We sort the indexes according to their similarity to the query image, and grab the top 5 results (which are not our original query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = naive_similarity[query_id].sort_values().index.values[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now grab the corresponding images and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these results are super sketchy... They're not _bad_ exactly, but they're definitely not good. Playing with the results for a while, it's easy to spot where the approach succeeds and where the rough edges appear.\n",
    "\n",
    "### The problem with histograms\n",
    "If you've spent any amount of time exploring the collection, you know that _a lot_ of the images exist in a weird, sad, grubby, greyscale/sepia section of the colour space. In that space, the straight histogram comparison approach is perfectly sufficient (I was actually surprised by how good the results are for some of these query images).  \n",
    "The method falls down when 'unusual' colours towards the ends of the 3D colour space start appearing, especially when they exist in a narrow band of intensities.  \n",
    "Cosine similarity (and almost all other vector similarity metrics) assume that neighbouring elements in the vector represent distances along axes that are _orthogonal_, ie independent from one another. To cosine, the histogram bins for `red=222` and `red=223` are _entirely_ different colours, while we know that to our eyes they appear very similar. We want our system to know that neighbouring values along our colour axes are functionally the same, and should be scored as similar.\n",
    "\n",
    "# Smoothed histograms\n",
    "This problem might be solved by smoothing our histograms. By taking a moving average (with window size empirically chosen as `w=10`), we blur the distinction between `red=222` and `red=223` etc.  \n",
    "Surprisingly, numpy doesn't have a built in moving average function defined, so we'll use the following functions to do the operation for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(arr, w):\n",
    "    '''\n",
    "    Returns a moving average over a given array\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : numpy.array\n",
    "        input array\n",
    "    n : int\n",
    "        window size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    arr : numpy.array\n",
    "        input array with moving average applied\n",
    "    '''\n",
    "    cumsum = np.cumsum(arr)\n",
    "    return (cumsum[w:] - cumsum[:-w])[w - 1:] / w\n",
    "\n",
    "\n",
    "def smooth_histogram(hist, w=10):\n",
    "    '''\n",
    "    applies a moving average to a image histogram, retaining separation between\n",
    "    the 3 channels\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hist : list\n",
    "        flat input histogram of size=(768,)\n",
    "    n : int\n",
    "        window size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    arr : numpy.array\n",
    "        input array with moving average applied\n",
    "    '''\n",
    "    r, g, b = np.split(np.array(hist), 3)\n",
    "    return np.concatenate([moving_average(r, w), \n",
    "                           moving_average(g, w), \n",
    "                           moving_average(b, w)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in `smooth_histogram()` we're splitting the histogram into its three channels before applying the moving average and re-concatenating them into a single output array. We don't want to blur high-intensity reds and low-intensity blues together, so this extra step is necessary.\n",
    "\n",
    "Let's apply the smoothing process to our histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_histograms = [smooth_histogram(h) for h in histograms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_similarity = pd.DataFrame(data=[[cosine(h_1, h_2) \n",
    "                                        for h_1 in smooth_histograms] \n",
    "                                       for h_2 in tqdm(smooth_histograms)],\n",
    "                                 index=image_ids,\n",
    "                                 columns=image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = smooth_similarity[query_id].sort_values().index.values[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are at least as good as those from the raw histograms, which is reassuring. We'll have to wait until the end of the notebook for a direct comparison though.\n",
    "\n",
    "# Dimensionality reduction\n",
    "Another plausible solution to the non-orthogonality of our colour space is to work in some dimensionality reduction. We expect that most neighbours will be correlated with one another (hence the smoothing in the last section), but it's harder to appreciate which neighbourhoods of colour will be more tightly bunched.\n",
    "Dimensionality reduction techniques like PCA, t-SNE and UMAP are great at finding these correlated features in a high-dimensional space. By keeping the number of target dimensions relatively high (600 from 768) in this case, we restrict the chance of losing any information in the dimensionality reduction process and hopefully retain most of the 'useful' information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = np.array(histograms)\n",
    "histograms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_histograms = UMAP(n_components=600).fit_transform(histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vectors now no longer represent ordered lists of pixel intensities - they're a blur of the 600 most 'useful' aggregated features that could be extracted from the original space. That said, they're still tied to image ids and can be compared to one another in exactly the same way as before. Let's produce our similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_similarity = pd.DataFrame(data=[[cosine(h_1, h_2) \n",
    "                                         for h_1 in reduced_histograms] \n",
    "                                        for h_2 in tqdm(reduced_histograms)],\n",
    "                                  index=image_ids,\n",
    "                                  columns=image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and run a test query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = reduced_similarity[query_id].sort_values().index.values[1:6]\n",
    "\n",
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct comparison\n",
    "Now that we've exhausted approaches to comparing histograms, let's compare the results to one another with the same query image to get a sense of each method's strengths, weaknesses and peculiarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = naive_similarity[query_id].sort_values().index.values[1:6]\n",
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = smooth_similarity[query_id].sort_values().index.values[1:6]\n",
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = reduced_similarity[query_id].sort_values().index.values[1:6]\n",
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The results from the three approaches are all quite similar, while also being similarly inconsistent.  \n",
    "On balance, I think the smoothed histogram approach provides the best results. It's good at matching within the greyscale/sepia band of colour space, and it most consistently incorporates colours from outside the band into its results. The dimensionality reduction technique provides surprisingly erratic results - I'm not sure why at this stage.\n",
    "\n",
    "\n",
    "Whatever the case may be within this histogram-matching experiment, none of the results are really good enough, and there are plenty of other approaches that we could take. We'll explore some alternatives in the next few notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
