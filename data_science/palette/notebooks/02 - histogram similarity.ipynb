{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity\n",
    "Now that we can produce colour palettes for images, we can move on to the second task - asserting similarity between images based on the colours within them.  \n",
    "For the task of producing notebooks, researching previous literature alone was sufficient to produce satisfactory results. However, because of the difference between our domain and more typical image datasets, I think it's worth implementing a few different approaches in code to determine which is most appropriate/effective similarity measure. We'll start with histograms.\n",
    "\n",
    "### Image histograms\n",
    "As we saw in the last notebook, digital images are composed of pixels and the colour of those pixels can be represented by three numbers (alternatively seen as coordinates in colour space). We can stack the pixels in an image to produce a table of three columns or channels (traditionally R, G, and B, where each channel can take on a value between 0 and 255 denoting its intensity). \n",
    "A common technique to assert the 'makeup' of an image is to produce a _histogram_ of these channels, counting the number of times that each intensity appears in each channel. Our goal in this notebook is to determine an effective way of comparing these histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (20, 15)\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from umap import UMAP\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets randomly load in a few images and display them to get a visual sense of the distribution of colours/tones/styles across our chosen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 1000\n",
    "path_to_images = '../data/small_images/'\n",
    "\n",
    "random_ids = np.random.choice(os.listdir(path_to_images), \n",
    "                              n_images, \n",
    "                              replace=False)\n",
    "\n",
    "image_dict = {}\n",
    "for image_id in tqdm(random_ids):\n",
    "    try: \n",
    "        image = Image.open(path_to_images + image_id)\n",
    "        if len(np.array(image).shape) != 3:\n",
    "            image = Image.fromarray(np.stack((image,)*3, -1))\n",
    "        image_dict[image_id] = image\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "image_ids = list(image_dict.keys())\n",
    "images = list(image_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 75\n",
    "size = int(n_images ** 0.5)\n",
    "\n",
    "height = int(resolution * size)\n",
    "width = int(resolution * size)\n",
    "\n",
    "big_image = np.empty((height, width, 3)).astype(np.uint8)\n",
    "grid = np.array(list(itertools.product(range(size), range(size))))\n",
    "sq_images = [image.resize((resolution, resolution)) for image in images]\n",
    "\n",
    "for pos, image in zip(grid, sq_images):\n",
    "    block_t, block_l = pos * resolution\n",
    "    block_b, block_r = (pos + 1) * resolution\n",
    "    \n",
    "    big_image[block_t : block_b, block_l : block_r] = np.array(image)\n",
    "\n",
    "Image.fromarray(big_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting histograms\n",
    "Let's produce a histogram for a random image to get a feel for the kind of data we'll be working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[np.random.choice(len(images))]\n",
    "hist = image.histogram()\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is what our raw histogram data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(hist).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows the three 256-length arrays concatenated together to form a 768-length array. Here it is split out into its three colour channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b = np.split(np.array(hist), 3)\n",
    "\n",
    "pd.DataFrame({'r': r, 'g': g, 'b': b}).plot(color=['#333399', \n",
    "                                                   '#339933', \n",
    "                                                   '#993333']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A naive start\n",
    "Lets blunder straight in with the simplest approach possible. We'll produce a historgram for each image as one long 756-dimensional vector and then get the cosine similarity of each image with every other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = [image.histogram() for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_similarity = pd.DataFrame(data=pairwise_distances(histograms, \n",
    "                                                        metric='cosine'),\n",
    "                                index=image_ids,\n",
    "                                columns=image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can display the similarity matrix as a heatmap, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(naive_similarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = dict(zip(image_ids, images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our similarity matrix to look up the most similar images to a given images. We select a random image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then grab the column in the matrix which holds similarity measures for our `query_id`. We sort the indexes according to their similarity to the query image, and grab the top 5 results (which are not our original query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = naive_similarity[query_id].sort_values().index.values[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now grab the corresponding images and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are super sketchy... They're not _bad_ exactly, but they're definitely not good. Playing with the results for a while, it's easy to spot where the approach succeeds and where the rough edges appear.\n",
    "\n",
    "### The problem with histograms\n",
    "If you've spent any amount of time exploring the collection, you know that _a lot_ of the images exist in a weird, sad, grubby, greyscale/sepia part of the colour space. In that space, the straight histogram comparison approach is perfectly sufficient (I was actually surprised by how good the results are for some of these query images).  \n",
    "The method falls down when 'unusual' colours towards the edges of the colour space start appearing, especially when they exist in a narrow band of intensities.  \n",
    "Cosine similarity (and almost all other vector similarity metrics) assume that neighbouring elements in the vector represent distances along axes that are _orthogonal_, ie independent from one another. To cosine, the histogram bins for `red=222` and `red=223` are therefore _entirely_ different colours, while we know that to our eyes they appear very similar. We want our system to know that neighbouring values along our colour axes are functionally the same, and should be scored as similar.\n",
    "\n",
    "# Smoothed histograms\n",
    "This problem might be solved by smoothing our histograms. By taking a moving average (with window size empirically chosen as `w=10`), we blur the distinction between `red=222` and `red=223` etc.  \n",
    "Surprisingly, numpy doesn't have a built in moving average function defined, so we'll use the following functions to do the operation for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(arr, w):\n",
    "    '''\n",
    "    Returns a moving average over a given array\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : numpy.array\n",
    "        input array\n",
    "    n : int\n",
    "        window size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    arr : numpy.array\n",
    "        input array with moving average applied\n",
    "    '''\n",
    "    cumsum = np.cumsum(arr)\n",
    "    return (cumsum[w:] - cumsum[:-w])[w - 1:] / w\n",
    "\n",
    "\n",
    "def smooth_histogram(hist, w=10):\n",
    "    '''\n",
    "    applies a moving average to a image histogram, \n",
    "    retaining separation between the 3 channels\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hist : list\n",
    "        flat input histogram of size=(768,)\n",
    "    n : int\n",
    "        window size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    arr : numpy.array\n",
    "        input array with moving average applied\n",
    "    '''\n",
    "    r, g, b = np.split(np.array(hist), 3)\n",
    "    return np.concatenate([moving_average(r, w), \n",
    "                           moving_average(g, w), \n",
    "                           moving_average(b, w)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in `smooth_histogram()` we're splitting the histogram into its three channels before applying the moving average and re-concatenating them into a single output array. We don't want to blur high-intensity reds and low-intensity blues together, so this extra step is necessary.\n",
    "\n",
    "Let's apply the smoothing process to all of our histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_histograms = [smooth_histogram(h) for h in histograms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_similarity = pd.DataFrame(data=pairwise_distances(smooth_histograms, \n",
    "                                                         metric='cosine'),\n",
    "                                 index=image_ids,\n",
    "                                 columns=image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = smooth_similarity[query_id].sort_values().index.values[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are at least as good as those from the raw histograms, which is reassuring. We'll have to wait until the end of the notebook for a direct comparison though.\n",
    "\n",
    "# Dimensionality reduction\n",
    "Another plausible solution to the non-orthogonality of our colour space is to work in some dimensionality reduction. We expect that most neighbours will be correlated with one another (hence the smoothing with constant window size in the last section), but it's harder to appreciate which neighbourhoods of colour will be more tightly bunched, ie where/when we should widen or shrink the window.  \n",
    "Dimensionality reduction techniques like PCA, t-SNE and UMAP are great at finding these correlated features in a high-dimensional space. By keeping the number of target dimensions relatively high in this case (going to 600 from 768), we restrict the chance of losing any important information in the dimensionality reduction process and hopefully retain most of the what's 'useful'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = np.array(histograms)\n",
    "histograms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_histograms = UMAP(n_components=600).fit_transform(histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vectors now no longer represent ordered lists of pixel intensities - they're a blur of the 600 most 'useful' aggregated features that could be extracted from the original space. That said, they're still tied to image ids and can be compared to one another in exactly the same way as before. Let's produce our similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_similarity = pd.DataFrame(data=pairwise_distances(reduced_histograms, \n",
    "                                                          metric='cosine'),\n",
    "                                  index=image_ids,\n",
    "                                  columns=image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and run a test query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = reduced_similarity[query_id].sort_values().index.values[1:6]\n",
    "\n",
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct comparison\n",
    "Now that we've exhausted approaches to comparing histograms, let's compare the results to one another with the same query image to get a sense of each method's strengths, weaknesses and peculiarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = naive_similarity[query_id].sort_values().index.values[1:6]\n",
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = smooth_similarity[query_id].sort_values().index.values[1:6]\n",
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = reduced_similarity[query_id].sort_values().index.values[1:6]\n",
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The results from the three approaches are all quite similar, while also being similarly inconsistent.  \n",
    "On balance, I think the smoothed histogram approach provides the best results. It's good at matching within the greyscale/sepia band of colour space, and it most consistently incorporates colours from outside the band into its results. The dimensionality reduction technique provides surprisingly erratic results - I'm not sure why at this stage.\n",
    "\n",
    "\n",
    "Whatever the case may be within this histogram-matching experiment, none of the results are really good enough, and there are plenty of other approaches that we could take. We'll explore some alternatives in the next few notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
