{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity\n",
    "Now that we can produce colour palettes for images, we can move on to the second task - asserting similarity between images based on the colours present within them.  \n",
    "For the task of producing notebooks, researching previous literature alone was sufficient to produce satisfactory results. However, because of the difference between our domain and more typical image datasets, I think it's worth implementing a few different approaches in code to determine which is most appropriate/effective. We'll start with histograms.\n",
    "\n",
    "### Image histograms\n",
    "As we saw in the last notebook, images are composed of pixels, and the colour of those pixels can be represented by three numbers (alternatively seen as coordinates in colour space). We can stack the pixels in an image to produce a table of three columns or channels (traditionally R, G, and B, where each channel can take on a value between 0 and 255 denoting its intensity). \n",
    "A common technique to assert the 'makeup' of an image is to produce a _histogram_ of these channels, counting the number of times that each intensity appears in each channel. Our goal in this notebook is to determine an effective way of comparing these histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (20, 15)\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cosine\n",
    "from umap import UMAP\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets randomly load in a few images and get a visual sense of the distribution of colours/tones/styles across our chosen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 1000\n",
    "path_to_images = '../data/small_images/'\n",
    "\n",
    "image_ids = np.random.choice(os.listdir(path_to_images), n_images, replace=False)\n",
    "images = [Image.open(path_to_images + image_id) for image_id in tqdm(image_ids)]\n",
    "images = [Image.fromarray(np.stack((image,)*3, -1))\n",
    "          if len(np.array(image).shape) != 3 else image\n",
    "          for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 75\n",
    "size = int(n_images ** 0.5)\n",
    "\n",
    "height = int(resolution * size)\n",
    "width = int(resolution * size)\n",
    "\n",
    "big_image = np.empty((height, width, 3)).astype(np.uint8)\n",
    "grid = np.array(list(itertools.product(range(size), range(size))))\n",
    "sq_images = [image.resize((resolution, resolution)) for image in images]\n",
    "\n",
    "for pos, image in zip(grid, sq_images):\n",
    "    block_t, block_l = pos * resolution\n",
    "    block_b, block_r = (pos + 1) * resolution\n",
    "    \n",
    "    big_image[block_t : block_b, block_l : block_r] = np.array(image)\n",
    "\n",
    "Image.fromarray(big_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[np.random.choice(len(images))]\n",
    "hist = image.histogram()\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is what our raw histogram data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(hist).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here it is split out into its three colour channels in the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b = np.split(np.array(hist), 3)\n",
    "\n",
    "pd.DataFrame({'r': r, 'g': g, 'b': b}).plot(color=['#333399', '#339933', '#993333']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A naive start\n",
    "Lets blunder straight in with the simplest approach possible. We'll produce a historgram for each image as one long 756-dimensional vector and then brute force the cosine similarity of each image with every other image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = [image.histogram() for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_similarity = pd.DataFrame(data=[[cosine(h_1, h_2)\n",
    "                                       for h_1 in histograms] \n",
    "                                      for h_2 in tqdm(histograms)],\n",
    "                                index=image_ids,\n",
    "                                columns=image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can display the similarity matrix as a heatmap, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(naive_similarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = dict(zip(image_ids, images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now pretty easy to use our similarity matrix to look up the most similar images to a given images. We select a random image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then grab the column in the matrix which holds similarity measures for our `query_id`. We sort the indexes according to their similarity to the query image, and grab the top 5 results (which are not our original query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = naive_similarity[query_id].sort_values().index.values[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now grab the corresponding images and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these results are super sketchy... They're not _bad_ exactly, but they're definitely not good. Playing with the results for a while, it's easy to spot where the approach succeeds and where the rough edges appear.\n",
    "\n",
    "### The problem with histograms\n",
    "If you've spent any amount of time exploring the collection, you know that _a lot_ of the images exist in a weird, sad, grubby, greyscale/sepia section of the colour space. In that space, the histogram approach is perfectly sufficient (I was actually surprised by how good the results for some of these query images are).  \n",
    "The method falls down when \n",
    "cosine similarity (and almost all other vector similarity metrics) assume that \n",
    "\n",
    "To cosine, `red=222` and `red=223` are _entirely_ different colours.\n",
    "\n",
    "# Smoothed histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(arr, n):\n",
    "    '''\n",
    "    Returns a moving average over a given array\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : numpy.array\n",
    "        input array\n",
    "    n : int\n",
    "        window size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    arr : numpy.array\n",
    "        input array with moving average applied\n",
    "    '''\n",
    "    cumsum = np.cumsum(arr)\n",
    "    return (cumsum[n:] - cumsum[:-n])[n - 1:] / n\n",
    "\n",
    "\n",
    "def smooth_histogram(hist, n=10):\n",
    "    '''\n",
    "    applies a moving average to a image histogram, retaining separation between\n",
    "    the 3 channels\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hist : list\n",
    "        flat input histogram of size=(768,)\n",
    "    n : int\n",
    "        window size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    arr : numpy.array\n",
    "        input array with moving average applied\n",
    "    '''\n",
    "    r, g, b = np.split(np.array(hist), 3)\n",
    "    return np.concatenate([moving_average(r, n), \n",
    "                           moving_average(g, n), \n",
    "                           moving_average(b, n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_histograms = [smooth_histogram(h) for h in histograms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_similarity = pd.DataFrame(data=[[cosine(h_1, h_2) \n",
    "                                        for h_1 in smooth_histograms] \n",
    "                                       for h_2 in tqdm(smooth_histograms)],\n",
    "                                 index=image_ids,\n",
    "                                 columns=image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(smooth_similarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = smooth_similarity[query_id].sort_values().index.values[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "We expect that most neighbours will be correlated with one another, but it's harder to appreciate which neighbourhoods will be more tightly bunched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = np.array(histograms)\n",
    "histograms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_histograms = UMAP(n_components=600).fit_transform(histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_similarity = pd.DataFrame(data=[[cosine(h_1, h_2) \n",
    "                                         for h_1 in reduced_histograms] \n",
    "                                        for h_2 in tqdm(reduced_histograms)],\n",
    "                                  index=image_ids,\n",
    "                                  columns=image_ids)\n",
    "\n",
    "sns.heatmap(reduced_similarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = reduced_similarity[query_id].sort_values().index.values[1:6]\n",
    "\n",
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# direct comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(image_ids)\n",
    "image_dict[query_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = naive_similarity[query_id].sort_values().index.values[1:6]\n",
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_ids = smooth_similarity[query_id].sort_values().index.values[1:6]\n",
    "similar_images = [image_dict[id].resize((300, 300)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) for image in similar_images]).reshape(300, 1500, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
