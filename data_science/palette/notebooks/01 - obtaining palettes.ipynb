{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining image colour palettes\n",
    "If we're going to search the collection by colour palette, we first need to be able to extract palettes from images. How the search happens (and whether it involves the palettes at all) is almost irrelevant at this stage. We know that colour palettes are going to be an integral part of whatever the final product of this project becomes, so we need them to be able to extract them.\n",
    "\n",
    "Our goal in this first notebook is just to extract a few of the dominant colours from a given image. There are a few plausible approaches to this task, but rather than explore all of them through implementation, I've read up on them in detail and decided on what I think is the most appropriate method before starting.\n",
    "\n",
    "### The process\n",
    "The basic process is as follows: \n",
    "- Turn the image into a numpy array of shape $(h, w, 3)$, where $h$ and $w$ are the height and width of the image, and the 3 denotes the dimensions of our colour space <sup id=\"a1\">[1](#f1)</sup> \n",
    "- Reshape the array, going from 3D to 2D, with rows representing individual pixels and columns representing the three colour channels, ie. an array of shape $(h\\times w, 3)$\n",
    "- Treat those three channels as axes in a 3D coordinate space, and each row as a point within that space. The distance between points should then represent the difference between colours: close points are similar colours, distant points are very different colours.\n",
    "- Use k-means clustering to obtain 5 distinct groups of pixels in colour space. \n",
    "- Return the center of each cluster. This set of 5 points in colour space make up the palette for the given image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading in an example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_images = '../data/small_images/'\n",
    "image_id = np.random.choice(os.listdir(path_to_images))\n",
    "image = Image.open(path_to_images + image_id)\n",
    "\n",
    "if len(np.array(image).shape) != 3:\n",
    "    image = Image.fromarray(np.stack((image,)*3, -1))\n",
    "\n",
    "print(image_id.replace('.jpg', ''))\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll resize the image to reduce the overall number of pixels. Using a large input array will give us more fidelity to the original image and a lower chance of missing colour details, but will significantly increase the computational cost when performing the k-means clustering. We'll also transform the pixels from RGB to LAB space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 100\n",
    "image = image.resize((image_size, image_size), \n",
    "                     resample=Image.BILINEAR)\n",
    "lab_image = rgb2lab(np.array(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our image is in numpy array format, it's easy to get it into the $(h \\times w, 3)$ shape we need to treat pixels as individual points in colour space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pixels = lab_image.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fit 5 clusters to our pixel data using `sklearn`'s k-means implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "cluster = (KMeans(n_clusters=n_clusters).fit(lab_pixels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coordinates of each cluster center are an integral part of [how k-means clustering works](https://en.wikipedia.org/wiki/K-means_clustering), so getting hold of them is also super easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have these coordinates in colour space, we just need to build an array to display them neatly. All we're doing below is building a solid block of colour for each colour in our palette (an $(n \\times n \\times 3)$ array where $n$ is the size of the colour block and each 3-vector is filled with our palette colour, transformed back into RGB space). Those blocks can then be stacked together to form a palette!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = (np.hstack([(lab2rgb(np.array(colour.tolist() * image_size * image_size)\n",
    "                               .reshape(image_size, image_size, 3)) * 255)\n",
    "                      .astype(np.uint8)\n",
    "                      for colour in cluster.cluster_centers_])\n",
    "           .reshape((image_size, image_size * n_clusters, 3)))\n",
    "\n",
    "Image.fromarray(palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra stuff\n",
    "We can bundle this process up into a pair of functions with nice, tweakable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_palette(image, palette_size=5, image_size=75):\n",
    "    '''\n",
    "    Return n dominant colours for a given image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : PIL.Image\n",
    "        The image for which we want to create a palette of dominant colours\n",
    "    palette_size : \n",
    "        The number of dominant colours to extract\n",
    "    image_size : \n",
    "        Images are resized and squared by default to reduce processing time.\n",
    "        This value sets the side-length of the square. Higher values will \n",
    "        indrease fidelity,  \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    palette : np.array\n",
    "        palette coordinates in LAB space\n",
    "    '''\n",
    "    image = image.resize((image_size, image_size))\n",
    "    lab_image = rgb2lab(np.array(image)).reshape(-1, 3)\n",
    "    clusters = KMeans(n_clusters=palette_size).fit(lab_image)\n",
    "    return clusters.cluster_centers_\n",
    "\n",
    "\n",
    "def display_palette(palette_colours, image_size=100):\n",
    "    '''\n",
    "    Return n dominant colours for a given image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    palette_colours : np.array\n",
    "        palette coordinates in LAB space\n",
    "    image_size : \n",
    "        The size of each palette colour swatch to be returned\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    palette : PIL.Image\n",
    "        image of square colour swatches\n",
    "    '''\n",
    "    palette_size=len(palette_colours)\n",
    "    \n",
    "    stretched_colours = [(lab2rgb(np.array(colour * image_size * image_size *5)\n",
    "                                  .reshape(image_size*5, image_size, 3)) * 255)\n",
    "                         .astype(np.uint8) \n",
    "                         for colour in palette_colours]\n",
    "    \n",
    "    palette_array = (np.hstack(stretched_colours)\n",
    "                     .reshape((image_size*5, \n",
    "                               image_size * palette_size, \n",
    "                               3)))\n",
    "\n",
    "    return Image.fromarray(palette_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted previously<sup>[1](#f1)</sup>, we're actually working in non-RGB colour space here. However, we can quite easily return the colours as RGB coordinates, as we do when we build the palette image to be displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_colours = [((lab2rgb(np.array(colour)\n",
    "                         .reshape(1, 1, 3)) * 255)\n",
    "                .astype(np.uint8)\n",
    "                .squeeze())\n",
    "               for colour in cluster.cluster_centers_]\n",
    "\n",
    "\n",
    "for colour in rgb_colours:\n",
    "    print(colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also return them as HEX values, which is useful in a few contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hex(rgb_list):\n",
    "    r, g, b = [int(round(channel)) for channel in rgb_list]\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(r, g, b)\n",
    "\n",
    "for colour in rgb_colours:\n",
    "    print(rgb_to_hex(colour))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Footnotes\n",
    "<sup id=\"f1\">1</sup> The most commonly used colour space is RGB, as images are naturally encoded in RGB for digital presentation. We'll actually be using CIELAB space in this project for various reasons. You don't really worry about this, but notebook 00 has some more detailed reasoning if you're interested. [â†©](#a1)</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
