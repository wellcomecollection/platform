{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining image colour palettes\n",
    "If we're going to search the collection by colour palette, we first need to be able to extract those palettes from images. How the search happens (and whether it involves the palettes at all) is almost irrelevant at this stage. We know that colour palettes are going to be an integral part of whatever this experience turns into, so we need them.\n",
    "\n",
    "Our goal in this first notebook is just to extract a few of the dominant colours from a given image. There are several possible approaches to this, but rather than explore all of them through implementation, I've read up on them in detail and decided on what I think is the most appropriate method beforehand.  \n",
    "If you're interested, here are a few links to things I've read in that research process:\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "### The process\n",
    "The basic process is as follows: \n",
    "- turn the image into a numpy array of shape $(h, w, 3)$, where $h$ and $w$ are the height and width of the image, and the third element representing the dimensions of our colour space <sup id=\"a1\">[1](#f1)</sup> \n",
    "- reshape that array into 2D array of with three columns representing the three colour channels, ie. $(h\\times w, 3)$\n",
    "- treat those three channels as axes in a 3D coordinate space, and each row as a point within that space. The distance between points should then represent the difference between colours; close points are similar colours, distant points are very different colours.\n",
    "- Use k-means clustering to obtain the 5 distinct groups of pixels in colour space. \n",
    "- Return the `cluster_centers` of the dominant groupings. This is the palette for the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's start by loading in an example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_images = '../data/small_images/'\n",
    "image_id = np.random.choice(os.listdir(path_to_images))\n",
    "image = Image.open(path_to_images + image_id)\n",
    "\n",
    "if len(np.array(image).shape) != 3:\n",
    "    image = Image.fromarray(np.stack((image,)*3, -1))\n",
    "\n",
    "print(image_id.replace('.jpg', ''))\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 100\n",
    "image = image.resize((image_size, image_size))\n",
    "lab_image = rgb2lab(np.array(image)).reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "cluster = (KMeans(n_clusters=n_clusters)\n",
    "           .fit(lab_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = [colour.tolist() for colour in cluster.cluster_centers_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = (np.hstack([(lab2rgb(np.array(colour * image_size * image_size)\n",
    "                               .reshape(image_size, image_size, 3)) * 255)\n",
    "                      .astype(np.uint8)\n",
    "                      for colour in colours])\n",
    "           .reshape((image_size, image_size * n_clusters, 3)))\n",
    "\n",
    "Image.fromarray(palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can bundle this process up into a pair of functions with easily-tweakable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_palette(image, palette_size=5, image_size=75):\n",
    "    image = image.resize((image_size, image_size))\n",
    "    lab_image = rgb2lab(np.array(image)).reshape(-1, 3)\n",
    "    clusters = KMeans(n_clusters=palette_size).fit(lab_image)\n",
    "    return [colour.tolist() for colour in clusters.cluster_centers_]\n",
    "\n",
    "\n",
    "def display_palette(palette_colours, palette_size=5, image_size=100):\n",
    "    stretched_colours = [(lab2rgb(np.array(colour * image_size * image_size *5)\n",
    "                                  .reshape(image_size*5, image_size, 3)) * 255)\n",
    "                         .astype(np.uint8) \n",
    "                         for colour in palette_colours]\n",
    "    \n",
    "    palette_array = (np.hstack(stretched_colours)\n",
    "                     .reshape((image_size*5, \n",
    "                               image_size * palette_size, \n",
    "                               3)))\n",
    "\n",
    "    return Image.fromarray(palette_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted below<sup>[1](#f1)</sup>, we're actually working in non-RGB colour space here. However, we can quite easily return the palette colours as RGB coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_colours = [((lab2rgb(np.array(colour).reshape(1, 1, 3)) * 255).astype(np.uint8).squeeze().tolist())\n",
    "               for colour in colours]\n",
    "\n",
    "\n",
    "for colour in rgb_colours:\n",
    "    print(colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or as HEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hex(rgb_list):\n",
    "    r, g, b = [int(round(channel)) for channel in rgb_list]\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(r, g, b)\n",
    "\n",
    "for colour in rgb_colours:\n",
    "    print(rgb_to_hex(colour))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tada!\n",
    "\n",
    "#### Footnotes\n",
    "<sup id=\"f1\">1</sup> The colour space used is normally RGB as images are naturally encoded in RGB for digital presentation, though we'll actually be using CIELAB space in this project for various reasons. Don't worry about this for now - notebook 5 has some more detailed reasoning. [â†©](#a1)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
