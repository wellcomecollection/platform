{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D colour space \n",
    "As we've seen in previous notebooks, we can explore an image by the position of its pixels in an n-dimensional colour space. The 3D RGB space can be binned into sections as follows:\n",
    "\n",
    "![RGB space](https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/RGB_Cube_Show_lowgamma_cutout_a.png/1280px-RGB_Cube_Show_lowgamma_cutout_a.png)\n",
    "\n",
    "The underlying pixel positions remain continuous (or approximately continuous), but the view we obtain from a binned version of the space is more computationally manageable (a $(16 \\times 16 \\times 16)$ binning of the space produces 4096 degrees of freedom, while the original $(256 \\times 256 \\times 256)$ gives us 16777216 to deal with). It also gives a more intuitive, blurred view of the similarity of neighbouring colours to one another.\n",
    "\n",
    "Let's start by loading in some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from umap import UMAP\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 5000\n",
    "path_to_images = '../data/small_images/'\n",
    "\n",
    "random_ids = np.random.choice(os.listdir(path_to_images), \n",
    "                              n_images, \n",
    "                              replace=False)\n",
    "\n",
    "image_dict = {}\n",
    "for image_id in tqdm(random_ids):\n",
    "    try: \n",
    "        image = Image.open(path_to_images + image_id)\n",
    "        if len(np.array(image).shape) != 3:\n",
    "            image = Image.fromarray(np.stack((image,)*3, -1))\n",
    "        image_dict[image_id] = image\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "image_ids = list(image_dict.keys())\n",
    "images = list(image_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each pixel in the image is treated as a point in 3d space. we evenly bin that 3d space and produce counts of the pixels appearing in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_size = 75\n",
    "\n",
    "pixel_lists = [(np.array(image.resize((small_size, small_size)))\n",
    "                .reshape(-1, 3)) for image in images]\n",
    "\n",
    "pixel_dict = dict(zip(image_ids, pixel_lists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "talk about the importance of resizing here - if we don't, this next process is _painfully_ slow. do some optimisation of the value of `small_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 16\n",
    "r = range(step_size)\n",
    "\n",
    "bins = [str(list(bin)) for bin in list(itertools.product(r, r, r))]\n",
    "bin_counts = pd.DataFrame(index=bins)\n",
    "\n",
    "for image_id, image in tqdm(pixel_dict.items()):\n",
    "    binned_pixels = (image / step_size).astype(np.uint8).tolist()\n",
    "    bin_strings = list(map(str, binned_pixels))\n",
    "    unique, counts = np.unique(bin_strings, return_counts=True)\n",
    "    bin_counts[image_id] = pd.Series(dict(zip(unique, counts)))\n",
    "\n",
    "bin_counts = bin_counts.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = UMAP().fit_transform(bin_counts.T.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=embedding[:, 0], \n",
    "            y=embedding[:, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = pd.DataFrame(data=pairwise_distances(bin_counts.T, \n",
    "                                                  metric='cosine'),\n",
    "                          index=bin_counts.columns,\n",
    "                          columns=bin_counts.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(similarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = np.random.choice(bin_counts.columns)\n",
    "image_dict[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 200\n",
    "n_similar = 10\n",
    "\n",
    "most_similar_ids = similarity[id].sort_values().index.values[1 : n_similar + 1]\n",
    "similar_images = [image_dict[id].resize((resolution, resolution)) for id in most_similar_ids]\n",
    "Image.fromarray(np.hstack([np.array(image) \n",
    "                           for image in similar_images])\n",
    "                .reshape(resolution, n_similar * resolution, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the results here are definitely better than those produced by previous approaches, but the hard boundary between bins is a bit ugly and frustrating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick transformation from RGB to LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
